name: Daily Data Core
'on':
  schedule:
    - cron: '0 5 * * *'
  workflow_dispatch:

env:
  # Environment configuration
  ENVIRONMENT: prod

  # Destination configuration
  DESTINATION__FILESYSTEM__BUCKET_URL: s3://prod/base/
  DESTINATION__FILESYSTEM__CREDENTIALS__ENDPOINT_URL: ${{secrets.FILESYSTEM_ENDPOINT_URL }}
  DESTINATION__FILESYSTEM__CREDENTIALS__AWS_ACCESS_KEY_ID: ${{secrets.FILESYSTEM_AWS_ACCESS_KEY_ID }}
  DESTINATION__FILESYSTEM__CREDENTIALS__AWS_SECRET_ACCESS_KEY: ${{secrets.FILESYSTEM_AWS_SECRET_ACCESS_KEY }}
  DESTINATION__FILESYSTEM__CREDENTIALS__REGION_NAME: eu-west-1
  DESTINATION__FILESYSTEM__KWARGS__USE_SSL: false

  # Home Assistant source configuration - using simpler env var names that dlt looks for
  SOURCES__HOME_ASSISTANT_HOST: ${{ secrets.HOME_ASSISTANT_HOST }}
  SOURCES__HOME_ASSISTANT_PORT: ${{ secrets.HOME_ASSISTANT_PORT }}
  SOURCES__HOME_ASSISTANT_TOKEN: ${{ secrets.HOME_ASSISTANT_TOKEN }}

  # SPIIR source configuration
  SOURCES__SPIIR_BASE_URL: ${{ secrets.SPIIR_BASE_URL }}
  SOURCES__SPIIR_EMAIL: ${{ secrets.SPIIR_EMAIL }}
  SOURCES__SPIIR_PASSWORD: ${{ secrets.SPIIR_PASSWORD }}

  # Todoist source configuration
  SOURCES__TODOIST_URL: ${{ secrets.TODOIST_URL }}
  SOURCES__TODOIST_TOKEN: ${{ secrets.TODOIST_TOKEN }}

  # Dawa source configuration
  SOURCES__DAWA_DAWA_BASE_URL: https://api.dataforsyningen.dk
  SOURCES__DAWA_DUCKDB_ENDPOINT: ${{ secrets.DUCKDB_ENDPOINT }}
  SOURCES__DAWA_DUCKDB_KEY_ID: ${{ secrets.DUCKDB_KEY_ID }}
  SOURCES__DAWA_DUCKDB_SECRET: ${{ secrets.DUCKDB_SECRET }}
  SOURCES__DAWA_DUCKDB_REGION: eu-west-1
  SOURCES__DAWA_DUCKDB_USE_SSL: false
  SOURCES__DAWA_DUCKDB_URL_STYLE: path

  # Grist source configuration
  SOURCES__GRIST_BASE_URL: ${{ secrets.GRIST_BASE_URL }}
  SOURCES__GRIST_API_TOKEN: ${{ secrets.GRIST_API_TOKEN }}

  # Rebrickable source configuration
  SOURCES__REBRICKABLE_BASE_URL: ${{ secrets.REBRICKABLE_BASE_URL }}
  SOURCES__REBRICKABLE_API_KEY: ${{ secrets.REBRICKABLE_API_KEY }}
  SOURCES__REBRICKABLE_DUCKDB_ENDPOINT: ${{ secrets.DUCKDB_ENDPOINT }}
  SOURCES__REBRICKABLE_DUCKDB_KEY_ID: ${{ secrets.DUCKDB_KEY_ID }}
  SOURCES__REBRICKABLE_DUCKDB_SECRET: ${{ secrets.DUCKDB_SECRET }}
  SOURCES__REBRICKABLE_DUCKDB_REGION: eu-west-1
  SOURCES__REBRICKABLE_DUCKDB_USE_SSL: false
  SOURCES__REBRICKABLE_DUCKDB_URL_STYLE: path

  # DBT DuckDB configuration
  DBT_DUCKDB_S3_KEY_ID: ${{ secrets.DUCKDB_KEY_ID }}
  DBT_DUCKDB_S3_SECRET: ${{ secrets.DUCKDB_SECRET }}
  DBT_DUCKDB_S3_ENDPOINT: ${{ secrets.DUCKDB_ENDPOINT }}
  DBT_DUCKDB_S3_REGION: eu-west-1
  DBT_DUCKDB_S3_USE_SSL: false
  DBT_DUCKDB_S3_URL_STYLE: path


jobs:

  maybe_skip:
    runs-on: [self-hosted, linux, docker]
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
    - id: skip_check
      uses: fkirc/skip-duplicate-actions@v5
      with:
        concurrent_skipping: always
        skip_after_successful_duplicate: 'false'
        do_not_skip: '[]'

  run_home_assistant_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/home_assistant_source.py

  run_spiir_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/spiir_source.py

  run_todoist_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/todoist_source.py

  run_dawa_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/dawa_source.py

  run_grist_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/grist_source.py

  run_rebrickable_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/rebrickable_source.py

  run_calendar_pipeline:
    needs: maybe_skip
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DLT Project
      uses: ./.github/actions/setup-dlt-project
    - name: Run pipeline script
      run: |
        cd dlt_project
        uv run sources/calendar_source.py

  run_dbt_transformations:
    needs: [run_home_assistant_pipeline, run_spiir_pipeline, run_todoist_pipeline, run_dawa_pipeline, run_grist_pipeline, run_rebrickable_pipeline, run_calendar_pipeline]
    if: needs.maybe_skip.outputs.should_skip != 'true'
    runs-on: [self-hosted, linux, docker]
    steps:
    - name: Check out
      uses: actions/checkout@v3
    - name: Setup DBT Project
      uses: ./.github/actions/setup-dbt-project
    - name: Create profiles.yml from environment
      run: |
        cd dbt_project
        cat > profiles.yml << EOF
        dbt_project:
          outputs:
            prod:
              type: duckdb
              path: /tmp/duckdb.db
              threads: 4
              extensions:
                - httpfs
                - parquet
                - delta
                - spatial
              secrets:
                - type: s3
                  scope: "s3://prod"
                  key_id: "${DBT_DUCKDB_S3_KEY_ID}"
                  secret: "${DBT_DUCKDB_S3_SECRET}"
                  endpoint: "${DBT_DUCKDB_S3_ENDPOINT}"
                  region: "${DBT_DUCKDB_S3_REGION}"
                  use_ssl: ${DBT_DUCKDB_S3_USE_SSL}
                  url_style: "${DBT_DUCKDB_S3_URL_STYLE}"
          target: prod
        EOF
    - name: Run DBT deps
      run: |
        cd dbt_project
        uv run dbt deps
    - name: Run DBT transformations
      run: |
        cd dbt_project
        uv run dbt run --target prod